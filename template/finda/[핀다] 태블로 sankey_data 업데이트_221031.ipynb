{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c12870a",
   "metadata": {},
   "source": [
    "# [핀다] 태블로 sankey_data 업데이트_221031"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda4933",
   "metadata": {},
   "source": [
    "### 오류 방지 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f41e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 패키지 설치 코드 \n",
    "# !pip install warnings\n",
    "# !pip install pathlib\n",
    "# !pip install datetime\n",
    "# !piA install oauth2client\n",
    "# !pip install gspread\n",
    "# !pip install openpyxl\n",
    "# !pip install pyarrow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f27e9",
   "metadata": {},
   "source": [
    "- 위 패키지 설치 코드는 로컬에서 해당 파일을 최초로 실행할 때 한번만 실행해주시면 됩니다.\n",
    "- 코드 실행 시 아래 이미지와 같은 경고창이 뜨는 것은 문제가 되지 않으니 무시해주세요.\n",
    "    - <img src=\"https://i.ibb.co/JF0dpWY/requirement-alreay-satisfied.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723c89d",
   "metadata": {},
   "source": [
    "- 이후 아래 이미지와 같은 형식의 오류가 발생할 경우 `!pip install 패키지명` 형식의 코드 작성하여 패키지 추가 설치해주세요.\n",
    "    - <img src = 'https://ifh.cc/g/ymACFT.png' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f604195",
   "metadata": {},
   "source": [
    "### 디렉토리 설정\n",
    "- 아래 download_dir에 최종 결과파일을 다운받을 폴더 위치경로를 입력해주세요.\n",
    "- 경로 주소는 '.../.../...' 형식을 따라주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class directory:\n",
    "    dir_list = os.getcwd().split('\\\\')\n",
    "    dropbox_dir = '/'.join(dir_list[:dir_list.index('Dropbox (주식회사매드업)')+1])\n",
    "    # 드롭박스 폴더 위치경로\n",
    "    \n",
    "    download_dir = dropbox_dir + '/광고사업부/데이터컨설팅/Tableau/result/핀다/sankey'\n",
    "    # 최종 결과파일을 다운받을 폴더 위치경로\n",
    "\n",
    "dr = directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e77c3",
   "metadata": {},
   "source": [
    "### 날짜 설정\n",
    "- 보통 작일자 기준으로 요청주신 기간의 데이터를 출력하게 됩니다.\n",
    "- 날짜 조정이 필요한 경우 아래 변수 값을 수정하여 출력해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class report_date:\n",
    "    today = datetime.date.today()\n",
    "    # 오늘 날짜 ex> 2022-09-14\n",
    "    \n",
    "    # today = datetime.date(year = 2022, month = 8, day = 12)\n",
    "    # 다른 일자를 기준으로 추출하고 싶은 경우 위 코드 수정하여 활용\n",
    "    \n",
    "    day_1 = today - datetime.timedelta(1)\n",
    "    # 전일자 ex> 2022-09-13\n",
    "    \n",
    "    yearmonth = day_1.strftime('%Y%m')\n",
    "    # 년월 ex> 202209\n",
    "\n",
    "rdate = report_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84de84",
   "metadata": {},
   "source": [
    "### 구글 스프레드 시트 읽기\n",
    "- 특정 구글 스프레드 시트를 읽어오기 위해 활용하는 메소드 모음입니다.\n",
    "- dcteam@madup-355605.iam.gserviceaccount.com 계정에 참조하고자 하는 구글 시트 공유가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3298bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class spreadsheet:\n",
    "    def spread_document_read(self, url):\n",
    "        token_dir = dr.dropbox_dir + '/광고사업부/데이터컨설팅/token'\n",
    "        scope = ['https://spreadsheets.google.com/feeds',\n",
    "                 'https://www.googleapis.com/auth/drive']\n",
    "        json_file = token_dir + '/madup-355605-cd37b0ac201f.json'\n",
    "        credentials = ServiceAccountCredentials.from_json_keyfile_name(json_file, scope)\n",
    "        gc = gspread.authorize(credentials)\n",
    "        read = gc.open_by_url(url)\n",
    "        print('스프레드시트 읽기 완료')\n",
    "        return read\n",
    "    \n",
    "    def spread_sheet(self, doc, sheet_name, col_num=0, row_num=0):\n",
    "        while True :\n",
    "            try :\n",
    "                data_sheet = doc.worksheet(sheet_name)\n",
    "                data_sheet_read = data_sheet.get_all_values()\n",
    "                result = pd.DataFrame(data_sheet_read, columns=data_sheet_read[row_num]).iloc[row_num+1:, col_num:]\n",
    "            except :\n",
    "                print('API 오류로 15초 후 다시 시도 합니다.')\n",
    "                time.sleep(15)\n",
    "                continue\n",
    "            break\n",
    "        return result\n",
    "\n",
    "spreadsheet = spreadsheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e25ad7",
   "metadata": {},
   "source": [
    "### 코드\n",
    "- 전처리 자동화를 위한 코드로 임의 수정을 하실 경우 복사본 생성하여 진행해주시길 바랍니다.\n",
    "- 이외의 오류가 발생하거나 문제가 해결되지 않는 경우, 데컨팀에 문의주세요 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a20ee",
   "metadata": {},
   "source": [
    "- 아래 시트에 정보를 우선 기입한 후 아래 코드를 실행하셔야 정상 동작됩니다.\n",
    "    - https://docs.google.com/spreadsheets/d/1_-jgnU51smApXKQ4R8n0ek984s-4NQ1TfQefv_SbQKE/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tableau_info():\n",
    "    account_name = '핀다'\n",
    "    result_name = 'finda'\n",
    "\n",
    "tableau_info = tableau_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdeeba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv as pacsv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "prep_doc = spreadsheet.spread_document_read('https://docs.google.com/spreadsheets/d/1_-jgnU51smApXKQ4R8n0ek984s-4NQ1TfQefv_SbQKE/edit#gid=0')\n",
    "\n",
    "def get_custom_sheet(doc, sheet_name):\n",
    "    # 태블로 대시보드 컬럼 설정 불러오기\n",
    "    sheet_data = spreadsheet.spread_sheet(doc, sheet_name)\n",
    "\n",
    "    return sheet_data\n",
    "\n",
    "\n",
    "def get_raw_df(apps_dir, is_organic, required_date):\n",
    "    if is_organic == False:\n",
    "        dtypes = {\n",
    "            'attributed_touch_time': pa.string(),\n",
    "            'attributed_touch_type': pa.string(),\n",
    "            'install_time': pa.string(),\n",
    "            'event_time': pa.string(),\n",
    "            'event_name': pa.string(),\n",
    "            'media_source': pa.string(),\n",
    "            'adset': pa.string(),\n",
    "            'ad': pa.string(),\n",
    "            'campaign': pa.string(),\n",
    "            'appsflyer_id': pa.string(),\n",
    "            'is_retargeting': pa.string(),\n",
    "            'event_value': pa.string(),\n",
    "            'platform': pa.string()\n",
    "        }\n",
    "    else:\n",
    "        dtypes = {\n",
    "            'Attributed Touch Time': pa.string(),\n",
    "            'Attributed Touch Type': pa.string(),\n",
    "            'Install Time': pa.string(),\n",
    "            'Event Time': pa.string(),\n",
    "            'Event Name': pa.string(),\n",
    "            'Media Source': pa.string(),\n",
    "            'Campaign': pa.string(),\n",
    "            'AppsFlyer ID': pa.string(),\n",
    "            'Is Retargeting': pa.string(),\n",
    "            'Event Value': pa.string(),\n",
    "            'Platform': pa.string()\n",
    "        }\n",
    "\n",
    "    index_columns = list(dtypes.keys())\n",
    "    convert_ops = pacsv.ConvertOptions(column_types=dtypes, include_columns=index_columns)\n",
    "    ro = pacsv.ReadOptions(block_size=10 << 20)\n",
    "    table_list = []\n",
    "\n",
    "    date_check = required_date.strftime('%Y%m')\n",
    "    start_date = required_date.replace(day=1).strftime('%Y%m%d')\n",
    "    end_date = required_date.strftime('%Y%m%d')\n",
    "\n",
    "    files = os.listdir(apps_dir)\n",
    "    files = [f for f in files if '.csv' in f and str(f)[-12:-6] == date_check]\n",
    "    raw_files = [f for f in files if\n",
    "                 (int(str(f)[-12:-4]) >= int(start_date)) & (int(str(f)[-12:-4]) <= int(end_date))]\n",
    "\n",
    "    for f in raw_files:\n",
    "        temp = pacsv.read_csv(apps_dir + '/' + f, convert_options=convert_ops, read_options=ro)\n",
    "        table_list.append(temp)\n",
    "    table = pa.concat_tables(table_list)\n",
    "    raw_df = table.to_pandas()\n",
    "    if is_organic == False:\n",
    "        raw_df['is_organic'] = False\n",
    "    else:\n",
    "        raw_df = raw_df.rename(columns=\n",
    "                               {'Attributed Touch Time': 'attributed_touch_time',\n",
    "                                'Attributed Touch Type': 'attributed_touch_type',\n",
    "                                'Install Time': 'install_time',\n",
    "                                'Event Time': 'event_time',\n",
    "                                'Event Name': 'event_name',\n",
    "                                'Media Source': 'media_source',\n",
    "                                'Campaign': 'campaign', 'AppsFlyer ID': 'appsflyer_id',\n",
    "                                'Is Retargeting': 'is_retargeting',\n",
    "                                'Event Value': 'event_value',\n",
    "                                'Platform': 'platform'})\n",
    "        raw_df['is_organic'] = True\n",
    "\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "### finda 추가 필터링 조건 ###\n",
    "def finda_paid_prep(raw_df):\n",
    "    raw_df.loc[raw_df['attributed_touch_type']!='click', 'is_organic'] = True\n",
    "    raw_df.loc[(raw_df['platform']=='ios')&(raw_df['attributed_touch_time']==''), 'is_organic'] = False\n",
    "\n",
    "    # 모비데이즈 데이터 예외처리\n",
    "    raw_df_copy = raw_df.copy()\n",
    "    raw_df_copy = raw_df_copy.loc[raw_df_copy['media_source']!='']\n",
    "    raw_df_copy_dedup = raw_df_copy[['media_source', 'campaign', 'adset', 'ad']].drop_duplicates(['campaign', 'adset', 'ad'])\n",
    "    raw_df_copy_dedup = raw_df_copy_dedup.rename(columns = {'media_source' : 'media_source_find'})\n",
    "\n",
    "    raw_df_merge = raw_df.merge(raw_df_copy_dedup, on = ['campaign', 'adset', 'ad'], how = 'left')\n",
    "\n",
    "    raw_df_merge.loc[raw_df_merge['media_source']=='', 'media_source'] = raw_df_merge['media_source_find']\n",
    "\n",
    "    del raw_df_merge['media_source_find']\n",
    "    return raw_df_merge\n",
    "############################\n",
    "\n",
    "\n",
    "def raw_data_concat(apps_paid_dir, apps_organic_dir, media_filter, required_date):\n",
    "    if (apps_paid_dir != dr.dropbox_dir)&(apps_organic_dir != dr.dropbox_dir):\n",
    "        paid_df = get_raw_df(apps_paid_dir, False, required_date)\n",
    "        organic_df = get_raw_df(apps_organic_dir, True, required_date)\n",
    "        ### finda 추가 필터링 ###\n",
    "        paid_df = finda_paid_prep(paid_df)\n",
    "        #######################\n",
    "        raw_df = pd.concat([paid_df, organic_df], sort=False, ignore_index=True)\n",
    "    elif (apps_paid_dir != dr.dropbox_dir)&(apps_organic_dir == dr.dropbox_dir):\n",
    "        raw_df = get_raw_df(apps_paid_dir, False, required_date)\n",
    "        ### finda 추가 필터링 ###\n",
    "        raw_df = finda_paid_prep(raw_df)\n",
    "        #######################\n",
    "    elif (apps_paid_dir == dr.dropbox_dir)&(apps_organic_dir != dr.dropbox_dir):\n",
    "        raw_df = get_raw_df(apps_organic_dir, True, required_date)\n",
    "    else:\n",
    "        raise Exception('드롭박스 내 appsflyer 데이터 위치를 입력 해주세요.')\n",
    "\n",
    "    raw_df['is_retargeting'] = raw_df['is_retargeting'].str.lower()\n",
    "\n",
    "    raw_df[['attributed_touch_time', 'install_time', 'event_time']] = raw_df[\n",
    "        ['attributed_touch_time', 'install_time', 'event_time']].apply(pd.to_datetime)\n",
    "\n",
    "    raw_df['click_date'] = raw_df['attributed_touch_time'].dt.date\n",
    "    raw_df['click_hour'] = raw_df['attributed_touch_time'].dt.hour\n",
    "    raw_df['click_weekday'] = raw_df['attributed_touch_time'].dt.weekday\n",
    "    raw_df['event_date'] = raw_df['event_time'].dt.date\n",
    "    raw_df['event_hour'] = raw_df['event_time'].dt.hour\n",
    "    raw_df['event_weekday'] = raw_df['event_time'].dt.weekday\n",
    "    raw_df['CTET'] = raw_df['event_time'] - raw_df['attributed_touch_time']\n",
    "\n",
    "    raw_df = raw_df.sort_values(['event_time','attributed_touch_time'])\n",
    "    raw_df.index = range(0, len(raw_df))\n",
    "\n",
    "    # raw_df_dedup = raw_df.drop_duplicates(['event_time', 'event_name', 'appsflyer_id'], keep='last')\n",
    "    raw_df_dedup = raw_df.loc[~(raw_df['media_source'].isin(media_filter))]\n",
    "\n",
    "    return raw_df_dedup\n",
    "\n",
    "\n",
    "def campaign_name_exception(prep_doc, raw_df):\n",
    "    ### finda 추가 필터링 조건 ###\n",
    "        # 캠페인명 수정\n",
    "    raw_df.loc[raw_df['media_source'] != 'moloco_int', 'campaign'] = raw_df['campaign'].apply(lambda x: x.replace('MobidaysAgency_', 'Madit_'))\n",
    "    raw_df.loc[raw_df['media_source'] != 'moloco_int', 'campaign'] = raw_df['campaign'].apply(lambda x: x.replace('Mobi_', 'Madit_'))\n",
    "    raw_df.loc[raw_df['media_source'] == 'cauly_int', 'campaign'] = raw_df['campaign'].apply(lambda x: 'Madit_CAULY_LOAN_RT_AOS_CPC_220714' if x.startswith('99') else x)\n",
    "    raw_df.loc[raw_df['media_source'] == 'tnk_int', 'campaign'] = 'Madit_TNK_LOAN_NU_AOS_REWARD-CPA_220715'\n",
    "        # 특정 캠페인 구분 organic으로 변경\n",
    "    raw_df.loc[(raw_df['media_source'] == 'kakao_int')&(raw_df['campaign']=='kakao_biz_loancontract'), 'is_organic'] = True\n",
    "    raw_df.loc[(raw_df['media_source'] == 'kakao')&(raw_df['campaign'] != 'talk'), 'is_organic'] = True\n",
    "    ############################\n",
    "\n",
    "    campaign_mapping = get_custom_sheet(prep_doc, tableau_info.account_name)\n",
    "    media_source = campaign_mapping.media_source.unique()\n",
    "    campaign_dict = {}\n",
    "    for source in media_source:\n",
    "        campaign_temp = campaign_mapping.loc[campaign_mapping['media_source']==source][['before_campaign','after_campaign']].set_index('before_campaign').to_dict()\n",
    "        campaign_dict[source] = campaign_temp['after_campaign']\n",
    "\n",
    "    for media in campaign_dict.keys():\n",
    "        raw_df.loc[raw_df['media_source'] == media, 'campaign'] = raw_df['campaign'].apply(\n",
    "        lambda x: campaign_dict[media][x] if x in campaign_dict[media].keys() else x)\n",
    "\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "def sankey_data_prep(prep_doc, required_date, file_name):\n",
    "    sheet_data = get_custom_sheet(prep_doc, '가공조건')\n",
    "    info_data = sheet_data.loc[sheet_data['광고주'] == tableau_info.account_name]\n",
    "\n",
    "    apps_paid_dir = dr.dropbox_dir + info_data['paid_raw 데이터 위치'].iloc[0]\n",
    "    apps_organic_dir = dr.dropbox_dir + info_data['organic_raw 데이터 위치'].iloc[0]\n",
    "    if info_data['제외 매체'].iloc[0] == '':\n",
    "        media_filter = []\n",
    "    else:\n",
    "        media_filter = info_data['제외 매체'].iloc[0].strip().replace(', ',',').split(',')\n",
    "    raw_df = raw_data_concat(apps_paid_dir, apps_organic_dir, media_filter, required_date)\n",
    "\n",
    "    if info_data['캠페인명 가공여부'].iloc[0] == 'TRUE':\n",
    "        raw_df_exception = campaign_name_exception(prep_doc, raw_df)\n",
    "    else:\n",
    "        raw_df_exception = raw_df\n",
    "\n",
    "    target_event_list = info_data['타겟 이벤트'].iloc[0].strip().replace(', ',',').split(',')\n",
    "    event_data = raw_df_exception.loc[raw_df_exception['event_name'].isin(target_event_list)]\n",
    "\n",
    "    event_data.loc[pd.isnull(event_data['attributed_touch_time']), 'attributed_touch_time'] = event_data['install_time']\n",
    "    event_data['click_date'] = event_data['attributed_touch_time'].dt.date\n",
    "    event_data['click_weekday'] = event_data['attributed_touch_time'].dt.weekday\n",
    "    event_data = event_data.loc[event_data['attributed_touch_type']!='impression']\n",
    "\n",
    "\n",
    "    event_data['CTET'] = (event_data['event_time'] - event_data['attributed_touch_time']).apply(\n",
    "        lambda x: x.total_seconds() / 86400)\n",
    "    event_data['CTIT'] = (event_data['install_time'] - event_data['attributed_touch_time']).apply(\n",
    "        lambda x: x.total_seconds() / 86400)\n",
    "    event_data['ITET'] = (event_data['event_time'] - event_data['install_time']).apply(lambda x: x.total_seconds() / 86400)\n",
    "\n",
    "    ctet_limit = info_data['CTET 기여기간'].iloc[0]\n",
    "    ctit_limit = info_data['CTIT 기여기간'].iloc[0]\n",
    "    itet_limit = info_data['ITET 기여기간'].iloc[0]\n",
    "\n",
    "    if ctet_limit != '':\n",
    "        event_data = event_data.loc[event_data['CTET'] < float(ctet_limit)]\n",
    "    if ctit_limit != '':\n",
    "        event_data = event_data.loc[event_data['CTIT'] < float(ctit_limit)]\n",
    "    if itet_limit != '':\n",
    "        event_data = event_data.loc[event_data['ITET'] < float(itet_limit)]\n",
    "\n",
    "    event_data = event_data.loc[~event_data['media_source'].isin(['', 'restricted'])]\n",
    "    event_data['Cnt'] = 1\n",
    "    event_data['click_month'] = event_data['attributed_touch_time'].dt.month\n",
    "    event_data['event_month'] = event_data['event_time'].dt.month\n",
    "    event_data['UA / RE'] = event_data['is_retargeting'].apply(lambda x : 'RE' if x == 'true' else 'UA')\n",
    "\n",
    "    event_data_filtered = event_data[['UA / RE', 'media_source', 'click_month', 'click_date', 'click_weekday',\n",
    "                                      'event_month','event_date','event_weekday',\n",
    "                                      'event_name','platform','appsflyer_id','Cnt']]\n",
    "\n",
    "    event_data_pivot = event_data_filtered.pivot_table(index=['UA / RE', 'media_source', 'click_month', 'click_date', 'click_weekday',\n",
    "                                                              'event_month','event_date','event_weekday','platform','event_name'],\n",
    "                                                       aggfunc='sum').reset_index()\n",
    "\n",
    "\n",
    "    event_data_pivot = event_data_pivot.sort_values(['event_month','click_month', 'event_weekday','click_weekday'])\n",
    "\n",
    "    weekday_dict = {0: '월요일',\n",
    "                    1: '화요일',\n",
    "                    2: '수요일',\n",
    "                    3: '목요일',\n",
    "                    4: '금요일',\n",
    "                    5: '토요일',\n",
    "                    6: '일요일'}\n",
    "    event_data_pivot['click_weekday'] = event_data_pivot['click_weekday'].apply(lambda x: weekday_dict.get(x))\n",
    "    event_data_pivot['event_weekday'] = event_data_pivot['event_weekday'].apply(lambda x: weekday_dict.get(x))\n",
    "\n",
    "    event_data_pivot['click_month'] = event_data_pivot['click_month'].apply(lambda x: str(x) + \"월\")\n",
    "    event_data_pivot['event_month'] = event_data_pivot['event_month'].apply(lambda x: str(x) + \"월\")\n",
    "    event_data_pivot.to_excel(dr.download_dir + '/' + file_name, index=False, encoding='utf-8-sig')\n",
    "    print('download successful')\n",
    "\n",
    "def union_sandkey_data(required_date, file_name):\n",
    "    date_check = required_date.strftime('%Y')\n",
    "    total_df = pd.DataFrame()\n",
    "\n",
    "    files = os.listdir(dr.download_dir)\n",
    "    files = [f for f in files if '.xlsx' in f and str(f)[-11:-7] == date_check]\n",
    "    raw_files = [f for f in files]\n",
    "    for file in raw_files:\n",
    "        temp = pd.read_excel(dr.download_dir + '/' + file)\n",
    "        total_df = pd.concat([total_df, temp], axis=0)\n",
    "\n",
    "    total_df.to_excel(dr.download_dir + '/' + file_name, index=False, encoding='utf-8-sig')\n",
    "    print('union successful')\n",
    "\n",
    "\n",
    "file_name = f'{tableau_info.result_name}_event_flow_data_{rdate.yearmonth}.xlsx'\n",
    "sankey_data_prep(prep_doc, rdate.day_1, file_name)\n",
    "union_sandkey_data(rdate.day_1, f'{tableau_info.result_name}_event_flow_data_{rdate.day_1.year}_total.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88197b1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
